---
title: Trees
has_children: False
parent: Machine Learning
nav_order: 6
---

# Trees
- [Random Forest](https://en.wikipedia.org/wiki/Random_forest)

   One of the most common ensemble learning methods. This is just the wikipedia article, but it's pretty good!

- [Gradient Boosting from Scratch](https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d)
   Medium post showing how to train gradient boosted trees.

- [Cost-Complexity Pruning](http://mlwiki.org/index.php/Cost-Complexity_Pruning)

   The algorithm showing a way to prune trees after they are learned to combat overfitting. Little to no explanation.

- [Pruning a tree](https://www.youtube.com/watch?v=GfPR7Xhdokc)

   A youtube explaining how to prune a tree (*14 min*)

- [Cost- Complexity Pruning in scikit learn](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html)

   The library function in sklearn that prunes trees.

- [Pruning a random forest](https://beedotkiran.github.io/forest.html)

   Academic paper showing how to prune a random forest...

- [PyData Talk: Isolation Forests for Anomaly Detection](https://www.youtube.com/watch?v=RyFQXQf4w4w)

   The goal of the talk is twofold; on the one hand an in-depth introduction to the class of Isolation Forests and on the other hand a look at the process of extending existing methods to handle missing features and categorical data. The concepts in this talk are accompanied with a [GitHub implementation](https://github.com/cubonacci/mixed-anomaly). (p.s. standard Isolation Forests are part of [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) and described in [this](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf) academic paper.) (*24 mins*)
